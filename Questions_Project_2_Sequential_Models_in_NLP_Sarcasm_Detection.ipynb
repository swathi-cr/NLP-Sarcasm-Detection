{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Questions - Project 2 - Sequential Models in NLP - Sarcasm Detection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bI7SIeJ_oZMU"
      },
      "source": [
        "<img src=\"http://drive.google.com/uc?export=view&id=1tpOCamr9aWz817atPnyXus8w5gJ3mIts\" width=500px>\n",
        "\n",
        "Proprietary content. © Great Learning. All Rights Reserved. Unauthorized use or distribution prohibited."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eukag7wEoPZu"
      },
      "source": [
        "### Package Version:\n",
        "- tensorflow==2.2.0\n",
        "- pandas==1.0.5\n",
        "- numpy==1.18.5\n",
        "- google==2.0.3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pp68FAQf9aMN"
      },
      "source": [
        "# Sarcasm Detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEahVPtWX5ve"
      },
      "source": [
        "### Dataset\n",
        "\n",
        "#### Acknowledgement\n",
        "Misra, Rishabh, and Prahal Arora. \"Sarcasm Detection using Hybrid Neural Network.\" arXiv preprint arXiv:1908.07414 (2019).\n",
        "\n",
        "**Required Files given in below link.**\n",
        "\n",
        "https://drive.google.com/drive/folders/1xUnF35naPGU63xwRDVGc-DkZ3M8V5mMk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAk6BRUh8CqL"
      },
      "source": [
        "### Load Data (5 Marks)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kt-Iu1ZxY5pL",
        "outputId": "d036c150-ebc1-492d-c37f-ea5379b352ee"
      },
      "source": [
        "#Mounting the Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "7LatmYsCclOB",
        "outputId": "f7eb1eae-2545-4d94-e466-d31573f30212"
      },
      "source": [
        "#Change the current working to the Project Directory\n",
        "import os\n",
        "path='/content/drive/My Drive/Colab Notebooks/NLP Project 2'\n",
        "os.chdir(path)\n",
        "os.getcwd()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/My Drive/Colab Notebooks/NLP Project 2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8-PQsV0DrAZ"
      },
      "source": [
        "#Unzipping the file.\n",
        "import zipfile\n",
        "with zipfile.ZipFile('Data-20201127T155239Z-001.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "pyg0eBvqdv2T",
        "outputId": "e0d1edbf-e0de-40c7-cc9b-f104e078f422"
      },
      "source": [
        "#Importing Data from JSON file\n",
        "import pandas as pd\n",
        "Data_Set=pd.read_json('Data/Sarcasm_Headlines_Dataset.json', lines=True)\n",
        "Data_Set.head()"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article_link</th>\n",
              "      <th>headline</th>\n",
              "      <th>is_sarcastic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://www.huffingtonpost.com/entry/versace-b...</td>\n",
              "      <td>former versace store clerk sues over secret 'b...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://www.huffingtonpost.com/entry/roseanne-...</td>\n",
              "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>https://local.theonion.com/mom-starting-to-fea...</td>\n",
              "      <td>mom starting to fear son's web series closest ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>https://politics.theonion.com/boehner-just-wan...</td>\n",
              "      <td>boehner just wants wife to listen, not come up...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>https://www.huffingtonpost.com/entry/jk-rowlin...</td>\n",
              "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        article_link  ... is_sarcastic\n",
              "0  https://www.huffingtonpost.com/entry/versace-b...  ...            0\n",
              "1  https://www.huffingtonpost.com/entry/roseanne-...  ...            0\n",
              "2  https://local.theonion.com/mom-starting-to-fea...  ...            1\n",
              "3  https://politics.theonion.com/boehner-just-wan...  ...            1\n",
              "4  https://www.huffingtonpost.com/entry/jk-rowlin...  ...            0\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTIyOGvBHVPk"
      },
      "source": [
        "The JSON File has been etracted and data has been stored in Data Frame Data_Set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3jOELXwisZQ"
      },
      "source": [
        "# **Data Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAN3xoLkiqxg",
        "outputId": "31a05b64-952a-4692-9a75-5b90efe46fc8"
      },
      "source": [
        "print('Shape of the Dataset: {}'.format(Data_Set.shape))\n",
        "print('There are 26709 rows and 3 columns in the data')\n",
        "if Data_Set.isnull().sum(axis = 0).sum() <= 0:\n",
        "  print('There are no NULL values in the data')\n",
        "else:\n",
        "  print('There are NULL values in the data')"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of the Dataset: (26709, 3)\n",
            "There are 26709 rows and 3 columns in the data\n",
            "There are no NULL values in the data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4tIyzfyI_Qq",
        "outputId": "43db8398-fd46-484c-acfb-b273c41a3091"
      },
      "source": [
        "Data_Set.info()"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 26709 entries, 0 to 26708\n",
            "Data columns (total 3 columns):\n",
            " #   Column        Non-Null Count  Dtype \n",
            "---  ------        --------------  ----- \n",
            " 0   article_link  26709 non-null  object\n",
            " 1   headline      26709 non-null  object\n",
            " 2   is_sarcastic  26709 non-null  int64 \n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 626.1+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "071eTYCtJEYv",
        "outputId": "2ff4bf91-a001-452d-d350-10efde17e199"
      },
      "source": [
        "Data_Set.describe()"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>is_sarcastic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>26709.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.438953</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.496269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       is_sarcastic\n",
              "count  26709.000000\n",
              "mean       0.438953\n",
              "std        0.496269\n",
              "min        0.000000\n",
              "25%        0.000000\n",
              "50%        0.000000\n",
              "75%        1.000000\n",
              "max        1.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZsEPYFEHerT"
      },
      "source": [
        "There are 26709 rows and 3 columns in the data\n",
        "There are no NULL values in the data.\n",
        "The mean value is 0.43 Hence data is not highly skewed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owHYo4ofHy8Q"
      },
      "source": [
        "Replacing the shortcut words with the full form."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBVBFYGwPbRr"
      },
      "source": [
        "contractions = { \n",
        "\"ain't\": \"am not / are not / is not / has not / have not\",\n",
        "\"aren't\": \"are not / am not\",\n",
        "\"can't\": \"cannot\",\n",
        "\"can't've\": \"cannot have\",\n",
        "\"'cause\": \"because\",\n",
        "\"could've\": \"could have\",\n",
        "\"couldn't\": \"could not\",\n",
        "\"couldn't've\": \"could not have\",\n",
        "\"didn't\": \"did not\",\n",
        "\"doesn't\": \"does not\",\n",
        "\"don't\": \"do not\",\n",
        "\"hadn't\": \"had not\",\n",
        "\"hadn't've\": \"had not have\",\n",
        "\"hasn't\": \"has not\",\n",
        "\"haven't\": \"have not\",\n",
        "\"he'd\": \"he had / he would\",\n",
        "\"he'd've\": \"he would have\",\n",
        "\"he'll\": \"he shall / he will\",\n",
        "\"he'll've\": \"he shall have / he will have\",\n",
        "\"he's\": \"he has / he is\",\n",
        "\"how'd\": \"how did\",\n",
        "\"how'd'y\": \"how do you\",\n",
        "\"how'll\": \"how will\",\n",
        "\"how's\": \"how has / how is / how does\",\n",
        "\"I'd\": \"I had / I would\",\n",
        "\"I'd've\": \"I would have\",\n",
        "\"I'll\": \"I shall / I will\",\n",
        "\"I'll've\": \"I shall have / I will have\",\n",
        "\"I'm\": \"I am\",\n",
        "\"I've\": \"I have\",\n",
        "\"isn't\": \"is not\",\n",
        "\"it'd\": \"it had / it would\",\n",
        "\"it'd've\": \"it would have\",\n",
        "\"it'll\": \"it shall / it will\",\n",
        "\"it'll've\": \"it shall have / it will have\",\n",
        "\"it's\": \"it has / it is\",\n",
        "\"let's\": \"let us\",\n",
        "\"ma'am\": \"madam\",\n",
        "\"mayn't\": \"may not\",\n",
        "\"might've\": \"might have\",\n",
        "\"mightn't\": \"might not\",\n",
        "\"mightn't've\": \"might not have\",\n",
        "\"must've\": \"must have\",\n",
        "\"mustn't\": \"must not\",\n",
        "\"mustn't've\": \"must not have\",\n",
        "\"needn't\": \"need not\",\n",
        "\"needn't've\": \"need not have\",\n",
        "\"o'clock\": \"of the clock\",\n",
        "\"oughtn't\": \"ought not\",\n",
        "\"oughtn't've\": \"ought not have\",\n",
        "\"shan't\": \"shall not\",\n",
        "\"sha'n't\": \"shall not\",\n",
        "\"shan't've\": \"shall not have\",\n",
        "\"she'd\": \"she had / she would\",\n",
        "\"she'd've\": \"she would have\",\n",
        "\"she'll\": \"she shall / she will\",\n",
        "\"she'll've\": \"she shall have / she will have\",\n",
        "\"she's\": \"she has / she is\",\n",
        "\"should've\": \"should have\",\n",
        "\"shouldn't\": \"should not\",\n",
        "\"shouldn't've\": \"should not have\",\n",
        "\"so've\": \"so have\",\n",
        "\"so's\": \"so as / so is\",\n",
        "\"that'd\": \"that would / that had\",\n",
        "\"that'd've\": \"that would have\",\n",
        "\"that's\": \"that has / that is\",\n",
        "\"there'd\": \"there had / there would\",\n",
        "\"there'd've\": \"there would have\",\n",
        "\"there's\": \"there has / there is\",\n",
        "\"they'd\": \"they had / they would\",\n",
        "\"they'd've\": \"they would have\",\n",
        "\"they'll\": \"they shall / they will\",\n",
        "\"they'll've\": \"they shall have / they will have\",\n",
        "\"they're\": \"they are\",\n",
        "\"they've\": \"they have\",\n",
        "\"to've\": \"to have\",\n",
        "\"wasn't\": \"was not\",\n",
        "\"we'd\": \"we had / we would\",\n",
        "\"we'd've\": \"we would have\",\n",
        "\"we'll\": \"we will\",\n",
        "\"we'll've\": \"we will have\",\n",
        "\"we're\": \"we are\",\n",
        "\"we've\": \"we have\",\n",
        "\"weren't\": \"were not\",\n",
        "\"what'll\": \"what shall / what will\",\n",
        "\"what'll've\": \"what shall have / what will have\",\n",
        "\"what're\": \"what are\",\n",
        "\"what's\": \"what has / what is\",\n",
        "\"what've\": \"what have\",\n",
        "\"when's\": \"when has / when is\",\n",
        "\"when've\": \"when have\",\n",
        "\"where'd\": \"where did\",\n",
        "\"where's\": \"where has / where is\",\n",
        "\"where've\": \"where have\",\n",
        "\"who'll\": \"who shall / who will\",\n",
        "\"who'll've\": \"who shall have / who will have\",\n",
        "\"who's\": \"who has / who is\",\n",
        "\"who've\": \"who have\",\n",
        "\"why's\": \"why has / why is\",\n",
        "\"why've\": \"why have\",\n",
        "\"will've\": \"will have\",\n",
        "\"won't\": \"will not\",\n",
        "\"won't've\": \"will not have\",\n",
        "\"would've\": \"would have\",\n",
        "\"wouldn't\": \"would not\",\n",
        "\"wouldn't've\": \"would not have\",\n",
        "\"y'all\": \"you all\",\n",
        "\"y'all'd\": \"you all would\",\n",
        "\"y'all'd've\": \"you all would have\",\n",
        "\"y'all're\": \"you all are\",\n",
        "\"y'all've\": \"you all have\",\n",
        "\"you'd\": \"you had / you would\",\n",
        "\"you'd've\": \"you would have\",\n",
        "\"you'll\": \"you shall / you will\",\n",
        "\"you'll've\": \"you shall have / you will have\",\n",
        "\"you're\": \"you are\",\n",
        "\"you've\": \"you have\"\n",
        "}"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4_v50CsQFNB"
      },
      "source": [
        "def clean_text(text):\n",
        "  # Convert words to lower case\n",
        "  text = text.lower()\n",
        "  if True:\n",
        "    text = text.split()\n",
        "    new_text = []\n",
        "    for word in text:\n",
        "      if word in contractions:\n",
        "        new_text.append(contractions[word])\n",
        "      else:\n",
        "        new_text.append(word)\n",
        "      text = \" \".join(new_text)\n",
        "  return text"
      ],
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYxYsdzhQMN5",
        "outputId": "8b5ae4c5-fff5-453a-fa1d-3c1ace8fcef6"
      },
      "source": [
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords \n",
        "from pickle import dump, load\n",
        "nltk.download('stopwords')\n",
        "clean_headline = []\n",
        "for h in Data_Set.headline:\n",
        "  clean_headline.append(clean_text(h))\n"
      ],
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82HK_I19Qhnx"
      },
      "source": [
        " Data_Set['headline']=clean_headline"
      ],
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6pXf7A78E2H"
      },
      "source": [
        "### Drop `article_link` from dataset (5 Marks)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WUNHq5zEV0n"
      },
      "source": [
        "#Dropping Column article_link from dataset\n",
        "Data_Set.drop(columns=['article_link'],inplace=True)"
      ],
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "g5NYUEkIDLz0",
        "outputId": "90c508ec-a34e-4742-be25-9405826af030"
      },
      "source": [
        "#Printing top 5 records\n",
        "Data_Set.head(5)"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headline</th>\n",
              "      <th>is_sarcastic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>former versace store clerk sues over secret 'b...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>mom starting to fear son's web series closest ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>boehner just wants wife to listen, not come up...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            headline  is_sarcastic\n",
              "0  former versace store clerk sues over secret 'b...             0\n",
              "1  the 'roseanne' revival catches up to our thorn...             0\n",
              "2  mom starting to fear son's web series closest ...             1\n",
              "3  boehner just wants wife to listen, not come up...             1\n",
              "4  j.k. rowling wishes snape happy birthday in th...             0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0h6IOxU8OdH"
      },
      "source": [
        "### Get length of each headline and add a column for that (5 Marks)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLpiBRDmEV2l"
      },
      "source": [
        "#Creating the column to store headline length\n",
        "Data_Set[\"HeadLine_Length\"]= Data_Set[\"headline\"].str.len() "
      ],
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWKGJm4aBL9c",
        "outputId": "34e2cae3-63fe-4318-9f12-252f2f0bf371"
      },
      "source": [
        "print('Data with the Mininum HeadLine Length is:')\n",
        "print(Data_Set[Data_Set[\"HeadLine_Length\"]==Data_Set.HeadLine_Length.min()])\n",
        "print('\\nData with the Maximum HeadLine Length is:')\n",
        "print(Data_Set[Data_Set[\"HeadLine_Length\"]==Data_Set.HeadLine_Length.max()])"
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data with the Mininum HeadLine Length is:\n",
            "      headline  is_sarcastic  HeadLine_Length\n",
            "20551  bye bye             0                7\n",
            "\n",
            "Data with the Maximum HeadLine Length is:\n",
            "                                                headline  ...  HeadLine_Length\n",
            "19868  maya angelou, poet, author, civil rights activ...  ...              254\n",
            "\n",
            "[1 rows x 3 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "SRTAKFBgEVZ2",
        "outputId": "dbb8915a-6209-4915-bb0d-e87a4e307076"
      },
      "source": [
        "Data_Set.head(5)"
      ],
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headline</th>\n",
              "      <th>is_sarcastic</th>\n",
              "      <th>HeadLine_Length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>former versace store clerk sues over secret 'b...</td>\n",
              "      <td>0</td>\n",
              "      <td>78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
              "      <td>0</td>\n",
              "      <td>84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>mom starting to fear son's web series closest ...</td>\n",
              "      <td>1</td>\n",
              "      <td>79</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>boehner just wants wife to listen, not come up...</td>\n",
              "      <td>1</td>\n",
              "      <td>84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
              "      <td>0</td>\n",
              "      <td>64</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            headline  ...  HeadLine_Length\n",
              "0  former versace store clerk sues over secret 'b...  ...               78\n",
              "1  the 'roseanne' revival catches up to our thorn...  ...               84\n",
              "2  mom starting to fear son's web series closest ...  ...               79\n",
              "3  boehner just wants wife to listen, not come up...  ...               84\n",
              "4  j.k. rowling wishes snape happy birthday in th...  ...               64\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "z4qzfJAAIK6p",
        "outputId": "e6bc8b64-3d8e-4bdb-aba7-4d82139df8d0"
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "df=Data_Set.copy()\n",
        "df['is_sarcastic'].replace(0, 'No-Sarcasm',inplace=True)\n",
        "df['is_sarcastic'].replace(1, 'Sarcasm',inplace=True)\n",
        "count_df=pd.DataFrame(Data_Set[['headline','is_sarcastic']].groupby(['is_sarcastic']).count())\n",
        "print('There are {} records in dataset with no sarcasam'.format(count_df['headline'][0]))\n",
        "print('There are {} records in dataset with sarcasam\\n'.format(count_df['headline'][1]))\n",
        "plt.title('Sarcasm vs No-Sarcasm')\n",
        "sns.countplot(df.is_sarcastic,palette=\"Set1\")\n",
        "plt.show()"
      ],
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 14985 records in dataset with no sarcasam\n",
            "There are 11724 records in dataset with sarcasam\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5NnBG7OVu8g",
        "outputId": "5cd20360-cc36-4506-de7d-49c0d2e022d9"
      },
      "source": [
        "#Checking the data for special characters\n",
        "import string\n",
        "import numpy as np\n",
        "special_char=0\n",
        "alphabets=0\n",
        "digits=0\n",
        "char=0\n",
        "space=0\n",
        "l = []\n",
        "for i in Data_Set.headline:\n",
        "  for j in i:\n",
        "    char=char + 1\n",
        "    if(j.isalpha()): \n",
        "      alphabets = alphabets + 1\n",
        "    elif(j.isdigit()):\n",
        "      digits = digits + 1\n",
        "    elif(j.isspace()):\n",
        "      space=space+1\n",
        "    else:\n",
        "      special_char = special_char + 1\n",
        "      l.append(j)\n",
        "print('Out of {} Characters in the Headline data there are {} alphabets, {} digits ,{} spaces and {} special characters'.format(char,alphabets,digits,space,special_char))\n",
        "print('\\nUnique special characters are ')\n",
        "print(np.unique(l))"
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Out of 1637505 Characters in the Headline data there are 1358898 alphabets, 9070 digits ,240580 spaces and 28957 special characters\n",
            "\n",
            "Unique special characters are \n",
            "['!' '\"' '#' '$' '%' '&' \"'\" '(' ')' '*' '+' ',' '-' '.' '/' ':' ';' '='\n",
            " '>' '?' '@' '[' '\\\\' ']' '_' '{' '|' '}' '\\x97' '\\x99' '¡' '©' '¯' '°'\n",
            " '¿' '×' '̈' '\\u200b' '–' '—' '―' '“' '”' '…' '™']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfUJuTxadp7_"
      },
      "source": [
        "#replace all the special characters other than white space to blank space\n",
        "import re\n",
        "Data_Set_Copy=Data_Set.copy()\n",
        "Data_Set_Copy['headline']=Data_Set_Copy['headline'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x)))"
      ],
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "I4lkuriJoy31",
        "outputId": "76983efa-02e9-454e-f795-d64638e73e79"
      },
      "source": [
        "Data_Set_Copy.head(5)"
      ],
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headline</th>\n",
              "      <th>is_sarcastic</th>\n",
              "      <th>HeadLine_Length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>former versace store clerk sues over secret bl...</td>\n",
              "      <td>0</td>\n",
              "      <td>78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>the roseanne revival catches up to our thorny ...</td>\n",
              "      <td>0</td>\n",
              "      <td>84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>mom starting to fear sons web series closest t...</td>\n",
              "      <td>1</td>\n",
              "      <td>79</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>boehner just wants wife to listen not come up ...</td>\n",
              "      <td>1</td>\n",
              "      <td>84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>jk rowling wishes snape happy birthday in the ...</td>\n",
              "      <td>0</td>\n",
              "      <td>64</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            headline  ...  HeadLine_Length\n",
              "0  former versace store clerk sues over secret bl...  ...               78\n",
              "1  the roseanne revival catches up to our thorny ...  ...               84\n",
              "2  mom starting to fear sons web series closest t...  ...               79\n",
              "3  boehner just wants wife to listen not come up ...  ...               84\n",
              "4  jk rowling wishes snape happy birthday in the ...  ...               64\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMF-wjJ2aMwm"
      },
      "source": [
        "### Initialize parameter values\n",
        "- Set values for max_features, maxlen, & embedding_size\n",
        "- max_features: Number of words to take from tokenizer(most frequent words)\n",
        "- maxlen: Maximum length of each sentence to be limited to 25\n",
        "- embedding_size: size of embedding vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPw9gAN_EV6m"
      },
      "source": [
        "max_features = 10000\n",
        "maxlen = 25\n",
        "embedding_size = 200"
      ],
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZo2fcsPqXY2"
      },
      "source": [
        "**Splitting the Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ezr1mZMmUbNd",
        "outputId": "43da663e-93fa-4374-db19-93421002a9c3"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import to_categorical\n",
        "import numpy as np\n",
        "y=np.array(to_categorical(Data_Set_Copy[\"is_sarcastic\"].values))\n",
        "X=Data_Set_Copy.headline\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.30, random_state = 1)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train,y_train, test_size = 0.30, random_state = 1)\n",
        "print('\\nShape of the Train Data:')\n",
        "print(X_train.shape,y_train.shape)\n",
        "print('\\nShape of the Val Data:')\n",
        "print(X_val.shape,y_val.shape)\n",
        "print('\\nShape of the Test Data:')\n",
        "print(X_test.shape,y_test.shape)"
      ],
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Shape of the Train Data:\n",
            "(13087,) (13087, 2)\n",
            "\n",
            "Shape of the Val Data:\n",
            "(5609,) (5609, 2)\n",
            "\n",
            "Shape of the Test Data:\n",
            "(8013,) (8013, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sah2N5ssIWE8"
      },
      "source": [
        "Data is divided into three categories Train, Val & Test Data. There is 13087 records in Train, 5609 in Train and 8013 in Test."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9abSe-bM8fn9"
      },
      "source": [
        "### Apply `tensorflow.keras` Tokenizer and get indices for words (5 Marks)\n",
        "- Initialize Tokenizer object with number of words as 10000\n",
        "- Fit the tokenizer object on headline column\n",
        "- Convert the text to sequence\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghGIJ7PNWBPW",
        "outputId": "6733eb68-4531-4204-83e3-c2b1c13003f5"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "tokenizer = Tokenizer(num_words=10000, split=' ')\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "vocabulary=tokenizer.word_index\n",
        "print(\"The number of unique words in the text corpus dictionary : {}\".format(len(tokenizer.word_index)))\n",
        "X_train = tokenizer.texts_to_sequences(X_train)"
      ],
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of unique words in the text corpus dictionary : 19880\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsdZAhkqYvt9"
      },
      "source": [
        "X_val = tokenizer.texts_to_sequences(X_val)\n",
        "X_test = tokenizer.texts_to_sequences(X_test)"
      ],
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBm0xjvL7Vtc"
      },
      "source": [
        "# Creating a reverse dictionary\n",
        "reverse_word_map = dict(map(reversed, vocabulary.items()))\n",
        "\n",
        "# Function takes a tokenized sentence and returns the words\n",
        "def sequence_to_text(indexed_array):\n",
        "    # Looking up words in dictionary\n",
        "    data = [reverse_word_map.get(word) for word in indexed_array]\n",
        "    return(data)"
      ],
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXRXQC9ZcTyk",
        "outputId": "a0a9cd6b-0d8b-4c1e-c2ea-43c0978e503c"
      },
      "source": [
        "max_len_train = max(len(j) for j in X_train ) \n",
        "max_len_val = max(len(j) for j in X_val ) \n",
        "max_len_test = max(len(j) for j in X_test ) \n",
        "print('Maximum sentence length in Train is {}, Val is {} & Test is {}'.format(max_len_train,max_len_val,max_len_test))\n",
        "j=0\n",
        "for i in X_train:\n",
        "  if(len(i)==max_len_train):\n",
        "    Max_Value_Record=i\n",
        "    break\n",
        "  j=j+1\n",
        "\n",
        "#Converting the list of index arrays to words\n",
        "Max_Data=sequence_to_text(Max_Value_Record)\n",
        "\n",
        "print('The headline of the Maximum Record data is:')\n",
        "print(Max_Data)\n",
        "print('The sentiment for the Maximum Record data is: {}'.format(Data_Set_Copy['is_sarcastic'].iloc[j]))\n"
      ],
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Maximum sentence length in Train is 36, Val is 23 & Test is 28\n",
            "The headline of the Maximum Record data is:\n",
            "['occasionally', 'you', 'realize', 'someone', 'you', 'thought', 'was', 'a', 'dear', 'friend', 'is', 'actually', 'a', 'foe', 'their', 'true', 'character', 'finally', 'revealed', 'but', 'how', 'do', 'you', 'forgive', 'the', 'here', 'are', 'my', '10', 'steps', 'to', 'handling', 'betrayal', 'with', 'and', 'grace']\n",
            "The sentiment for the Maximum Record data is: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeZpwPO4bOkZ"
      },
      "source": [
        "### Pad sequences (5 Marks)\n",
        "- Pad each example with a maximum length\n",
        "- Convert target column into numpy array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOmjNg6csf1Q"
      },
      "source": [
        "y_train=np.array(y_train)\n",
        "y_val=np.array(y_val)\n",
        "y_test=np.array(y_test)"
      ],
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qV0K70E5c9Xl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c71244b-5c9a-46bf-e3df-84726db6f9d1"
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "#max_len_train=max_len_train+1\n",
        "X_train = pad_sequences(X_train,maxlen=max_len_train)\n",
        "print('Maximum Train Length post padding is {} and Mininum Train length post padding is {}'.format(max(len(i) for i in X_train),min(len(i) for i in X_train )))"
      ],
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Maximum Train Length post padding is 36 and Mininum Train length post padding is 36\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAjQlehaDxZU",
        "outputId": "db761eaf-470f-4710-d840-5bd0f4830271"
      },
      "source": [
        "print('Train Data after Padding is:\\n')\n",
        "print(X_train)"
      ],
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Data after Padding is:\n",
            "\n",
            "[[   0    0    0 ...  673 4914 1872]\n",
            " [   0    0    0 ...  674  780 9554]\n",
            " [   0    0    0 ...   29 1720 1587]\n",
            " ...\n",
            " [   0    0    0 ...    1  259  114]\n",
            " [   0    0    0 ... 1409   23 1496]\n",
            " [   0    0    0 ...    4 1535  341]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HIVquCinLOE",
        "outputId": "2e770057-142d-472f-b901-8e5b272b0888"
      },
      "source": [
        "X_val = pad_sequences(X_val,maxlen=max_len_train)\n",
        "print('Maximum Val Length post padding is {} and Mininum Val length post padding is {}'.format(max(len(i) for i in X_val),min(len(i) for i in X_val )))"
      ],
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Maximum Val Length post padding is 36 and Mininum Val length post padding is 36\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "roHZkI60ngUX",
        "outputId": "35a7145e-bc52-4357-ded9-f27a6fed4ad4"
      },
      "source": [
        "print('Val Data after Padding is:\\n')\n",
        "print(X_val)"
      ],
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Val Data after Padding is:\n",
            "\n",
            "[[   0    0    0 ...    4   12  303]\n",
            " [   0    0    0 ...    4  153 4890]\n",
            " [   0    0    0 ...   80  213   22]\n",
            " ...\n",
            " [   0    0    0 ...   49  220   83]\n",
            " [   0    0    0 ... 1246   85 2853]\n",
            " [   0    0    0 ...   13    8  809]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5urBg5pnoCl",
        "outputId": "b0f1b0b6-4f87-4b6c-97c4-1861f46fc877"
      },
      "source": [
        "X_test = pad_sequences(X_test,maxlen=max_len_train)\n",
        "print('Maximum Test Length post padding is {} and Mininum Test length post padding is {}'.format(max(len(i) for i in X_test),min(len(i) for i in X_test )))"
      ],
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Maximum Test Length post padding is 36 and Mininum Test length post padding is 36\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgCyzu25noOF",
        "outputId": "c14fcb7c-bd0f-4fd7-93e9-0732fd03ee2f"
      },
      "source": [
        "print('Test Data after Padding is:\\n')\n",
        "print(X_test)"
      ],
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Data after Padding is:\n",
            "\n",
            "[[   0    0    0 ...   62   83  585]\n",
            " [   0    0    0 ... 4123    8   11]\n",
            " [   0    0    0 ... 1462   21  684]\n",
            " ...\n",
            " [   0    0    0 ... 7871 3056   43]\n",
            " [   0    0    0 ...  470    3 2099]\n",
            " [   0    0    0 ...    5    3  212]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJLyKg-98rH_"
      },
      "source": [
        "### Vocab mapping\n",
        "- There is no word for 0th index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RN4f1jGMPn2W",
        "outputId": "8f104349-3ff1-4b63-84de-3af6aa96727b"
      },
      "source": [
        "print('Starting Index for the key is {} and value is {}'.format(min(reverse_word_map.keys()),reverse_word_map[min(reverse_word_map.keys())]))\n",
        "print('Ending Index for the key is {} and value is {}'.format(max(reverse_word_map.keys()),reverse_word_map[max(reverse_word_map.keys())]))"
      ],
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting Index for the key is 1 and value is to\n",
            "Ending Index for the key is 19880 and value is reopened\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRiNX58Rb3oJ"
      },
      "source": [
        "### Set number of words\n",
        "- Since the above 0th index doesn't have a word, add 1 to the length of the vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dfwq6ou8ck2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e469b26-7621-4500-a0d0-85a4b07badee"
      },
      "source": [
        "num_words = len(tokenizer.word_index) + 1\n",
        "print('Total Number of Words in the vocabulary is :{}'.format(num_words))\n",
        "vocab_length=num_words"
      ],
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Number of Words in the vocabulary is :19881\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUF1TuQa8ux0"
      },
      "source": [
        "### Load Glove Word Embeddings (5 Marks)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vq5AIfRtMeZh"
      },
      "source": [
        "EMBEDDING_FILE = 'Data/glove.6B.200d.txt'\n",
        "\n",
        "embeddings = {}\n",
        "for o in open(EMBEDDING_FILE):\n",
        "    word = o.split(\" \")[0]\n",
        "    # print(word)\n",
        "    embd = o.split(\" \")[1:]\n",
        "    embd = np.asarray(embd, dtype='float32')\n",
        "    # print(embd)\n",
        "    embeddings[word] = embd"
      ],
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prHSzdQUcZhm"
      },
      "source": [
        "### Create embedding matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elZ-T5aFGZmZ"
      },
      "source": [
        "# create a weight matrix for words in training docs\n",
        "embedding_matrix = np.zeros((num_words, 200))\n",
        "\n",
        "for word, i in tokenizer.word_index.items():\n",
        "\tembedding_vector = embeddings.get(word)\n",
        "\tif embedding_vector is not None:\n",
        "\t\tembedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 199,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RzyzeXhqaMq",
        "outputId": "bc6d8036-e353-4d26-fae7-62cd86eeafd0"
      },
      "source": [
        "embedding_matrix.shape"
      ],
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19881, 200)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 200
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7IbWuEX82Ra"
      },
      "source": [
        "### Define model (10 Marks)\n",
        "- Hint: Use Sequential model instance and then add Embedding layer, Bidirectional(LSTM) layer, flatten it, then dense and dropout layers as required. \n",
        "In the end add a final dense layer with sigmoid activation for binary classification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tv168Gmc3PY"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Dropout, LSTM, Bidirectional,Embedding\n",
        "model=Sequential()\n",
        "model.add(Embedding(vocab_length, embedding_size, input_length=max_len_train,weights = [embedding_matrix]))\n",
        "model.add(Bidirectional(LSTM(300,return_sequences=True)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(300,activation=\"softsign\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(2,activation=\"sigmoid\"))"
      ],
      "execution_count": 207,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hvIW01mxTzL",
        "outputId": "3acae651-2185-41f0-a2c2-78a7bb84cf0d"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_6 (Embedding)      (None, 36, 200)           3976200   \n",
            "_________________________________________________________________\n",
            "bidirectional_6 (Bidirection (None, 36, 600)           1202400   \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 21600)             0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 300)               6480300   \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 2)                 602       \n",
            "=================================================================\n",
            "Total params: 11,659,502\n",
            "Trainable params: 11,659,502\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoI7_8Y1cqTj"
      },
      "source": [
        "### Compile the model (5 Marks)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jJiPHeNoJ3U"
      },
      "source": [
        "model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])"
      ],
      "execution_count": 209,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7s4nmqcecw3a"
      },
      "source": [
        "### Fit the model (5 Marks)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NN789zNnJ5PL"
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "earlystop = EarlyStopping(patience = 5,monitor = 'val_accuracy')"
      ],
      "execution_count": 210,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xt9GdfZMxi__",
        "outputId": "3ac4546c-3ed9-4d26-edd9-886858d8bc18"
      },
      "source": [
        "model.fit(X_train,y_train,validation_split=0.1,epochs = 3, callbacks = [earlystop])"
      ],
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "369/369 [==============================] - 19s 51ms/step - loss: 0.4502 - accuracy: 0.7915 - val_loss: 0.3539 - val_accuracy: 0.8419\n",
            "Epoch 2/3\n",
            "369/369 [==============================] - 18s 48ms/step - loss: 0.2418 - accuracy: 0.9016 - val_loss: 0.3759 - val_accuracy: 0.8411\n",
            "Epoch 3/3\n",
            "369/369 [==============================] - 18s 48ms/step - loss: 0.1147 - accuracy: 0.9592 - val_loss: 0.4232 - val_accuracy: 0.8388\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1eacde6668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 211
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vMeRwCvGjsD",
        "outputId": "c05710f5-5f7d-488b-d3df-344cb4d5ffa0"
      },
      "source": [
        "val_result=model.evaluate(X_val, y_val)\n",
        "test_result=model.evaluate(X_test, y_test)"
      ],
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "176/176 [==============================] - 1s 5ms/step - loss: 0.4187 - accuracy: 0.8428\n",
            "251/251 [==============================] - 1s 4ms/step - loss: 0.4271 - accuracy: 0.8401\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKs6x4t6CCoN",
        "outputId": "da1ae097-86f1-46f0-b914-0ec8c0579246"
      },
      "source": [
        "print(\"Val Accuracy of model: {0:.2%}\".format(val_result[1]))\n",
        "print(\"Test Accuracy of model: {0:.2%}\".format(test_result[1]))"
      ],
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Val Accuracy of model: 84.28%\n",
            "Test Accuracy of model: 84.01%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N47eYVVd7m0-"
      },
      "source": [
        "**Predict on one sample**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ei4RkgEUAYeT"
      },
      "source": [
        "y_test_new=[]\n",
        "j=0\n",
        "for i in y_test:\n",
        "  if (y_test[j][0]==1):\n",
        "    y_test_new.append(0)\n",
        "  else:\n",
        "    y_test_new.append(1)\n",
        "  j=j+1"
      ],
      "execution_count": 214,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OcFXbmV5SCP",
        "outputId": "f9d141bb-0f77-46be-a841-fc40af53cf41"
      },
      "source": [
        "y_pred=model.predict(X_test)\n",
        "y_pred_new=[]\n",
        "j=0\n",
        "for i in y_pred:\n",
        "  if (y_pred[j][0]>0.5):\n",
        "    y_pred_new.append(0)\n",
        "  else:\n",
        "    y_pred_new.append(1)\n",
        "  j=j+1\n",
        "  \n",
        "print('Actual Output: ',y_test[3])\n",
        "print('Predicted Output: ',y_pred[3])"
      ],
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Actual Output:  [1. 0.]\n",
            "Predicted Output:  [0.85967773 0.15578331]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKQAU1mx6H88"
      },
      "source": [
        "from sklearn import metrics\n",
        "import pandas as pd\n",
        "accuracy_score_test=metrics.accuracy_score(y_test_new,y_pred_new)\n",
        "conf_metr=metrics.confusion_matrix(y_test_new,y_pred_new,labels=[1,0])\n",
        "df_conf_metr=pd.DataFrame(conf_metr,index = [i for i in [\"Actual 1\",\"Actual 0\"]],columns=[i for i in [\"Predict 1\",\"Predict 0\"]])"
      ],
      "execution_count": 216,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dMiSdqjc_TZ7",
        "outputId": "0f0dc38c-e354-4cb0-b5b5-ad79947aac77"
      },
      "source": [
        "print(\"Confusion Matrix :\")\n",
        "print(df_conf_metr)"
      ],
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix :\n",
            "          Predict 1  Predict 0\n",
            "Actual 1       2646        881\n",
            "Actual 0        395       4091\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqdO8URkFdd5"
      },
      "source": [
        "News Headlines dataset for Sarcasm Detection with Bi Directional LSTM is giving the test accuracy of 84.01 The model has the Val accuracy of 84.28.\n",
        "\n",
        "The model uses Sequential model with layers like Embedding Layer with the vocabulary size of 18315 and Embedding size of 200. Followed by Bidirectional LSTM Layer ,  Flatten Layer , Dense layer , Dropour Layer and Dense Layer with activation as Sigmoid.\n",
        "\n",
        "The model has correctly predicted the 2646 Sarcasm and 4091 Not Sarcasm.\n",
        "\n",
        "It has also predicted incorrectly 395 as Sarcasm and 881 as Not Sarcasm."
      ]
    }
  ]
}